{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. FEPAA LC 合并历史数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from datetime import datetime \r\n",
        "import pyspark.sql.functions as F    \r\n",
        "\r\n",
        "# todo 1:指定路径\r\n",
        "lc_month_path = 'abfss://test-data@dlsaaddpnorth3001.dfs.core.chinacloudapi.cn/test/WZX/01-FEPAA/FEPAA_LC_month.csv'\r\n",
        "lc_history_path = 'abfss://test-data@dlsaaddpnorth3001.dfs.core.chinacloudapi.cn/test/WZX/01-FEPAA/ods_fepaa_currency_lc_df.csv'\r\n",
        "lc_merge_path = 'abfss://test-data@dlsaaddpnorth3001.dfs.core.chinacloudapi.cn/test/WZX/01-FEPAA/ods_fepaa_currency_lc_new.csv'\r\n",
        "\r\n",
        "\r\n",
        "# todo 2:读取df\r\n",
        "df1 = spark.read.csv(lc_month_path,header=True)\r\n",
        "df2 = spark.read.csv(lc_history_path,header=True)\r\n",
        "\r\n",
        "# todo 3:合并数据\r\n",
        "df2 = df2.drop('etl_load_time').where(F.col('month')!='month')\r\n",
        "df_merger = df2.unionAll(df1).dropDuplicates()\r\n",
        "\r\n",
        "# todo 4:添加数据加载时间\r\n",
        "formatted_endtime = datetime.now()\r\n",
        "etl_load_time = formatted_endtime.strftime(\"%Y-%m-%d %H:%M:%S\")\r\n",
        "df = df_merger.withColumn('etl_load_time',F.lit(etl_load_time))\r\n",
        "\r\n",
        "# todo 5:写入文件\r\n",
        "df.coalesce(1).write.csv(lc_merge_path,mode='overwrite',header=True)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    }
  }
}