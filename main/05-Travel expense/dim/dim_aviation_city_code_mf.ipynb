{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\r\n",
        "import requests\r\n",
        "import json\r\n",
        "import pyspark.sql.functions as F\r\n",
        "import pyspark.sql.types as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def formatted_addr(addr):\r\n",
        "    addr_key = '1f206129ec240f1cc12be917b9615c0b'\r\n",
        "    _url = 'https://restapi.amap.com/v3/geocode/geo?address={}&output=JSON&key={}'.format(addr, addr_key)\r\n",
        "    respon = requests.get(_url)\r\n",
        "    response = json.loads(respon.content)\r\n",
        "    status = response['status']\r\n",
        "    info = response['info']\r\n",
        "    addr_data = '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '0.0,0.0'\r\n",
        "    if status == '1' and info == 'OK':\r\n",
        "        count = response['count']\r\n",
        "        if count == '1':\r\n",
        "            data = response[\"geocodes\"][0]\r\n",
        "            formatted_address = data[\"formatted_address\"]\r\n",
        "            country = data[\"country\"]\r\n",
        "            province = data[\"province\"]\r\n",
        "            city = data[\"city\"]\r\n",
        "            district = data[\"district\"]\r\n",
        "            location = data[\"location\"]\r\n",
        "            addr_data = str(formatted_address) + \"&\" + str(country) + \"&\" + str(province) + \"&\" + str(\r\n",
        "                city) + \"&\" + str(district) + \"&\" + str(location)\r\n",
        "        elif count == '0':\r\n",
        "            addr_data = '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '0.0,0.0'\r\n",
        "    elif status == '0' and info != 'OK':\r\n",
        "        addr_data = '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '' + \"&\" + '0.0,0.0'\r\n",
        "\r\n",
        "    r0 = addr_data.split('&')[0] # address\r\n",
        "    r1 = addr_data.split('&')[1] # country\r\n",
        "    r2 = addr_data.split('&')[2] # province\r\n",
        "    r3 = addr_data.split('&')[3] # city\r\n",
        "    r4 = addr_data.split('&')[4] # district\r\n",
        "    r5 = addr_data.split('&')[5] # Latitude and longitude\r\n",
        "    print(r0)\r\n",
        "    if r3 == '' or r3 == \"[]\":\r\n",
        "        r3 = addr.strip()\r\n",
        "    return r3\r\n",
        "# formatted_addr('Beijing and SHENZHEN')\r\n",
        "gd_udf = F.udf(formatted_addr,T.StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# todo 1： 读取数据\r\n",
        "read_path = 'abfss://data-warehouse-ods@dlsaaddpnorth3001.dfs.core.chinacloudapi.cn/ods_mau_bcd_aviation_city_code.csv'\r\n",
        "df = pd.read_csv(read_path,dtype=str)\r\n",
        "\r\n",
        "# todo 2：数据处理\r\n",
        "new_col = {\r\n",
        "    '三字代码'  : 'aviation_city_code'\r\n",
        "    ,'所属城市'  : 'city_name_local_language'\r\n",
        "    ,'英文名称'  : 'city_name_EN'\r\n",
        "    ,'所属国家'  : 'country_region_name'\r\n",
        "    ,'国家代码'  : 'country_region_code'\r\n",
        "}\r\n",
        "df.rename(columns=new_col,inplace=True)\r\n",
        "df['country_region_name'].replace('西藏','中国',inplace=True)\r\n",
        "df['city_name_local_language'] = df['city_name_local_language'].str.strip() # 去除行首空格\r\n",
        "df = df.reindex(columns=new_col.values())\r\n",
        "df = spark.createDataFrame(df)\r\n",
        "\r\n",
        "df = df.withColumn('city_name_local_language'\r\n",
        "                ,F.when(F.col('country_region_name')=='中国',gd_udf(F.col('city_name_local_language'))) \\\r\n",
        "                .otherwise(F.col('city_name_local_language')))\r\n",
        "display(df)\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 写入文件\r\n",
        "save_path = 'abfss://data-warehouse-dim@dlsaaddpnorth3001.dfs.core.chinacloudapi.cn/dim_aviation_city_code_mf.csv'\r\n",
        "df.toPandas().to_csv(save_path, mode='w',index=False, header=True)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}